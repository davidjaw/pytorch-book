# -*- coding: utf-8 -*-
"""CH4 - 多類別分類問題.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q4EHHs6x1QyiEqCBDDL6Coebae9KKDLt

# 第四章 - 多類別分類問題
"""

import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


def example_1():
    """### 4.1.2 卷積神經網路架構
    #### 範例2：建立一個網路模型輸入大小為28x28x4，並連接一層卷積層，再透過model.summary函數來觀察卷積層所使用的參數數量，如圖4-8所示。最後我們使用上方的參數計算公式，驗證參數數量是否和圖中顯示的1184一致，參數設定如下：
    * 輸入影像（Input）：28x28x4（長度, 寬度, 深度）。
    * 填補（Padding）：無。
    * 步幅（Stride）：1。
    * 卷積核數量（Kernel number）：32個（kernel_numbers）。
    * 卷積核大小（Kernel size）：3x3（〖kernel〗_height, kernel_width）。
    * 偏差值（Bias）：有。
    """

    class ExampleConvolutionNet(nn.Module):
      def __init__(self):
        super().__init__()
        self.relu = F.relu
        self.conv = nn.Conv2d(3, 32, 3, bias=True)
      def forward(self, x):
        x = self.relu(self.conv(x))
        return x

    input_size = (3, 28, 28)
    net = ExampleConvolutionNet()
    summary(net, input_size, device=device)


def example_2():
    """### 捲積範例
    先透過 `!wget` 下載圖片，預設會存在當前的資料夾中
    """
    # download lena.jpg from imgur
    # !wget https://i.imgur.com/gjeDs00.png

    """引入 library"""

    import torchvision.transforms as T
    from PIL import Image

    """讀取圖片，並將其灰階化、並透過 `unsqueeze` 新增維度以符合網路的輸入"""

    # read input lena image
    img = Image.open('gjeDs00.png')
    transform = T.Compose([T.Grayscale(), T.ToTensor()])
    img = transform(img)
    img = torch.unsqueeze(img, 0)
    img_out = img.clone().detach()

    """初始化 kernels"""

    # innitialize convolution kernel
    kernels = []
    kernels.append( torch.tensor([[[[1., 0, -1], [0, 0, 0], [-1, 0, 1]]]]) )
    kernels.append( torch.tensor([[[[-1., -1, -1], [-1, 8, -1], [-1, -1, -1]]]]) )
    kernels.append( torch.tensor([[[[0., -1, 0], [-1, 5, -1], [0, -1, 0]]]]) )
    kernels.append( torch.tensor([[[[1., 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16 )

    """分別對每個 kernel 進行捲積，並將其和原圖串聯"""

    for k in kernels:
      conv_img = F.conv2d(img, k, padding=1)
      img_out = torch.cat([img_out, conv_img], 3)

    # transpose to fit imshow
    img_out = torch.permute(img_out, [0, 2, 3, 1])

    import matplotlib.pyplot as plt
    figure_size = 5
    plt.figure(figsize=(figure_size * len(kernels), figure_size))
    plt.imshow(img_out[0, :, :, 0], interpolation='nearest', vmin=0, vmax=1, cmap='gray')


